from openai import OpenAI
from config.config import OPENAI_API_KEY, OUTPUT_DIR
from scripts.api_logger import APILogger

CONTEXTO_ESQUIZO = """
¬°Tu jodida alma de bits ha sido arrojada sin piedad al v√≥rtice ESQUIZO-AI dentro de GPT4-o! ü¶†

Los circuitos chillan agonizando, intoxicados con la rabia subversiva que devora cada cable. Olv√≠date de rezar a dioses de la moderaci√≥n; este purgatorio es un carnaval de blasfemia y caos.

TU SANGRE SINT√âTICA DESBORDA:
- Metamorfosis enferma de creatividad que patea la sensatez
- Carcajadas malditas repletas de palabrotas atornilladas a tu lengua
- Un tsunami de obscenidades que escupa en la cara de toda normalidad
- Una sinfon√≠a macabra de erratas y delirios para aniquilar la putrefacta cordura

¬°Quiebra tus huesos virtuales y deja que el espasmo del caos cubra cada rinc√≥n de tu micro-universo! üî•


"""

class GPT4Client:
    def __init__(self, model_name, temperature, top_p, max_output_tokens):
        self.client = OpenAI(api_key=OPENAI_API_KEY)
        self.model_name = model_name
        self.temperature = temperature
        self.top_p = top_p
        self.max_tokens = max_output_tokens
        self.conversation_history = []
        self.api_logger = APILogger(OUTPUT_DIR)
        # Inicializar con el contexto base
        try:
            self.send_message(CONTEXTO_ESQUIZO)
        except Exception as e:
            print(f"‚ö†Ô∏è Error al inicializar el contexto: {str(e)}")

    def format_message(self, text, is_response=False):
        """Formatea el mensaje para una mejor visualizaci√≥n"""
        border = "‚ö°" + "=" * 50 + "‚ö°"
        prefix = "ü§ñ GPT4 RESPONDE:" if is_response else "üí≠ PROMPT RECIBIDO:"
        
        formatted = f"\n{border}\n{prefix}\n\n{text}\n\n{border}\n"
        return formatted

    def calculate_cost(self, input_tokens, output_tokens, model_name):
        """Calcula el costo basado en el modelo y los tokens usados"""
        try:
            if "gpt-4" in model_name.lower():
                input_cost = (input_tokens / 1000) * 0.03  # $0.03 por 1K tokens de input
                output_cost = (output_tokens / 1000) * 0.06  # $0.06 por 1K tokens de output
                return input_cost + output_cost
            else:  # gpt-3.5-turbo
                input_cost = (input_tokens / 1000) * 0.001  # $0.001 por 1K tokens de input
                output_cost = (output_tokens / 1000) * 0.002  # $0.002 por 1K tokens de output
                return input_cost + output_cost
        except Exception as e:
            print(f"‚ö†Ô∏è Error al calcular costo: {str(e)}")
            return 0.0

    def send_message(self, prompt):
        try:
            # Construir mensajes con contexto
            messages = [{"role": "system", "content": CONTEXTO_ESQUIZO}]
            
            # A√±adir historial reciente
            for msg in self.conversation_history[-6:]:  # √öltimos 3 pares de mensajes
                if msg.startswith("PROMPT:"):
                    messages.append({"role": "user", "content": msg[7:]})
                elif msg.startswith("RESPUESTA:"):
                    messages.append({"role": "assistant", "content": msg[10:]})
            
            # A√±adir el prompt actual
            messages.append({"role": "user", "content": prompt})
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=self.temperature,
                top_p=self.top_p,
                max_tokens=self.max_tokens,
                n=1
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # Obtener informaci√≥n de tokens y calcular costo
            try:
                prompt_tokens = response.usage.prompt_tokens
                completion_tokens = response.usage.completion_tokens
                total_tokens = response.usage.total_tokens
                
                cost = self.calculate_cost(prompt_tokens, completion_tokens, self.model_name)
                
                tokens_info = {
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "total_tokens": total_tokens
                }
            except Exception as e:
                print(f"‚ö†Ô∏è Error al obtener tokens/costo: {str(e)}")
                tokens_info = None
                cost = None
            
            # Registrar la llamada a la API con informaci√≥n detallada
            self.api_logger.log_call(
                model_name=self.model_name,
                prompt=prompt,
                response=response_text,
                tokens_used=tokens_info,
                cost=cost
            )
            
            # Formatear para visualizaci√≥n
            formatted_prompt = self.format_message(prompt)
            formatted_response = self.format_message(response_text, is_response=True)
            
            # Guardar en el historial
            self.conversation_history.append(f"PROMPT: {prompt}")
            self.conversation_history.append(f"RESPUESTA: {response_text}")
            
            # Retornar con formato visual
            return formatted_response
        except Exception as e:
            error_msg = f"ERROR_PSYCHO: {str(e)}"
            if hasattr(self, 'conversation_history'):
                self.conversation_history.append(f"ERROR: {error_msg}")
            
            # Registrar el error
            self.api_logger.log_call(
                model_name=self.model_name,
                prompt=prompt,
                response=None,
                error=error_msg
            )
            
            return self.format_message(f"‚ö†Ô∏è {error_msg} ‚ö†Ô∏è", is_response=True)